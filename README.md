# Projet Machine Learning - Analyse Comportementale ClientÃ¨le Retail

## ğŸ“‹ Description

Ce projet vise Ã  analyser le comportement des clients d'une entreprise e-commerce de cadeaux pour :
- **Personnaliser** les stratÃ©gies marketing
- **RÃ©duire** le taux de dÃ©part des clients (churn)
- **Optimiser** le chiffre d'affaires

Le dataset contient **4 372 clients** avec **52 features** issues de transactions rÃ©elles.

---

## ğŸ“ Structure du Projet

```
projet_ml_retail/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # DonnÃ©es brutes originales
â”‚   â”‚   â””â”€â”€ retail_customers_COMPLETE_CATEGORICAL.csv
â”‚   â”œâ”€â”€ processed/                    # DonnÃ©es nettoyÃ©es
â”‚   â”‚   â””â”€â”€ retail_customers_CLEANED.csv
â”‚   â””â”€â”€ train_test/                   # DonnÃ©es splitÃ©es
â”‚       â”œâ”€â”€ X_train.csv
â”‚       â”œâ”€â”€ X_test.csv
â”‚       â”œâ”€â”€ y_train.csv
â”‚       â””â”€â”€ y_test.csv
â”œâ”€â”€ notebooks/                        # Notebooks Jupyter (prototypage)
â”œâ”€â”€ src/                              # Scripts Python (production)
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ models/                           # ModÃ¨les sauvegardÃ©s (.pkl, .joblib)
â”œâ”€â”€ app/                              # Application web (Flask)
â”œâ”€â”€ reports/                          # Rapports et visualisations
â”œâ”€â”€ requirements.txt                  # DÃ©pendances
â”œâ”€â”€ README.md                         # Documentation
â””â”€â”€ .gitignore
```

---

## ğŸš€ Installation

### 1. CrÃ©er l'environnement virtuel

```bash
# CrÃ©ation
python -m venv venv

# Activation (Windows)
venv\Scripts\activate

# Activation (Mac/Linux)
source venv/bin/activate
```

### 2. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 3. GÃ©nÃ©rer le fichier requirements.txt (si modifications)

```bash
pip freeze > requirements.txt
```

---

## ğŸ“Š DonnÃ©es

### DonnÃ©es Originales
- **Fichier** : `retail_customers_COMPLETE_CATEGORICAL.csv`
- **Lignes** : 4 372 clients
- **Colonnes** : 52 features + 1 target (Churn)

### DonnÃ©es NettoyÃ©es
- **Fichier** : `retail_customers_CLEANED.csv`
- **Lignes** : 4 372 clients
- **Colonnes** : 105 features + 1 target (Churn)
- **Split** : 80% Train (3 497) / 20% Test (875)

---

## ğŸ”§ Pipeline de Nettoyage

### Ã‰tape 1 : Imputation des Valeurs Manquantes

| Feature | MÃ©thode | Valeur | Description |
|---------|---------|--------|-------------|
| `Age` | MÃ©diane | 49.0 | 1 311 valeurs manquantes |
| `AvgDaysBetweenPurchases` | MÃ©diane | 1.15 | 79 valeurs manquantes |
| `SupportTicketsCount` | MÃ©diane | 2.0 | Outliers -1, 999 â†’ NaN |
| `SatisfactionScore` | Mode | 5.0 | Outliers -1, 99 â†’ NaN |

### Ã‰tape 2 : Parsing des Dates

- **Feature** : `RegistrationDate`
- **Formats traitÃ©s** : `"17/07/10"`, `"2010-10-04"`, `"10/18/2010"`
- **Nouvelles features crÃ©Ã©es** :
  - `RegYear` : AnnÃ©e d'inscription
  - `RegMonth` : Mois d'inscription
  - `RegDay` : Jour d'inscription
  - `RegWeekday` : Jour de la semaine (0=Lundi, 6=Dimanche)

### Ã‰tape 3 : Suppression des Features Inutiles

| Feature | Raison |
|---------|--------|
| `NewsletterSubscribed` | Valeur constante (toujours "Yes") |
| `LastLoginIP` | Non pertinent pour le ML |
| `CustomerID` | Identifiant unique |

### Ã‰tape 4 : Traitement des Outliers (MÃ©thode IQR)

Les outliers ont Ã©tÃ© limitÃ©s aux bornes IQR (Q1 - 1.5Ã—IQR, Q3 + 1.5Ã—IQR) pour :
- `MonetaryTotal`, `MonetaryAvg`, `MonetaryStd`
- `MonetaryMin`, `MonetaryMax`
- `TotalQuantity`, `AvgQuantityPerTransaction`
- `Age`

### Ã‰tape 5 : Gestion de la MulticolinÃ©aritÃ©

| Feature SupprimÃ©e | CorrÃ©lÃ©e avec | CorrÃ©lation |
|-------------------|---------------|-------------|
| `MonetaryAvg` | `MonetaryTotal` | Ã‰levÃ©e |
| `UniqueInvoices` | `Frequency` | 1.0 |
| `UniqueDescriptions` | `UniqueProducts` | 1.0 |
| `MinQuantity` | `MaxQuantity` | 0.961 |
| `AvgProductsPerTransaction` | `AvgLinesPerInvoice` | 0.963 |
| `NegativeQuantityCount` | `CancelledTransactions` | 1.0 |

### Ã‰tape 6 : Encodage des Variables CatÃ©gorielles

#### Encodage Ordinal (5 variables)

| Feature | Mapping |
|---------|---------|
| `SpendingCategory` | Low=0, Medium=1, High=2, VIP=3 |
| `LoyaltyLevel` | Nouveau=0, Jeune=1, Ã‰tabli=2, Ancien=3 |
| `ChurnRiskCategory` | Faible=0, Moyen=1, Ã‰levÃ©=2, Critique=3 |
| `AgeCategory` | Inconnu=0, 18-24=1, ..., 65+=6 |
| `BasketSizeCategory` | Petit=0, Moyen=1, Grand=2 |

#### One-Hot Encoding (10 variables â†’ 70 colonnes)

- `RFMSegment` (3 colonnes)
- `CustomerType` (4 colonnes)
- `FavoriteSeason` (3 colonnes)
- `PreferredTimeOfDay` (3 colonnes)
- `Region` (12 colonnes)
- `WeekendPreference` (2 colonnes)
- `ProductDiversity` (2 colonnes)
- `Gender` (2 colonnes)
- `AccountStatus` (3 colonnes)
- `Country` (36 colonnes)

### Ã‰tape 7 : Scaling

- **MÃ©thode** : StandardScaler
- **Features** : 35 variables numÃ©riques
- **Transformation** : Moyenne = 0, Ã‰cart-type = 1

### Ã‰tape 8 : Train/Test Split

- **Ratio** : 80% Train / 20% Test
- **MÃ©thode** : StratifiÃ© sur la target `Churn`
- **Random State** : 42 (reproductibilitÃ©)

---

## ğŸ“ˆ Distribution de la Target

| Classe | Description | Proportion |
|--------|-------------|------------|
| 0 | Client fidÃ¨le | 66.7% |
| 1 | Client parti (Churn) | 33.3% |

---

## ğŸ’» Utilisation

### Charger les donnÃ©es nettoyÃ©es

```python
import pandas as pd

# Dataset complet
 df = pd.read_csv('data/processed/retail_customers_CLEANED.csv')

# Train/Test split
X_train = pd.read_csv('data/train_test/X_train.csv')
X_test = pd.read_csv('data/train_test/X_test.csv')
y_train = pd.read_csv('data/train_test/y_train.csv')
y_test = pd.read_csv('data/train_test/y_test.csv')
```

### EntraÃ®ner un modÃ¨le

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Initialiser le modÃ¨le
model = RandomForestClassifier(n_estimators=100, random_state=42)

# EntraÃ®ner
model.fit(X_train, y_train)

# PrÃ©dire
y_pred = model.predict(X_test)

# Ã‰valuer
print(classification_report(y_test, y_pred))
```

---

## ğŸ”¬ Features Principales

### Features NumÃ©riques (35)
- `Recency` : Jours depuis le dernier achat
- `Frequency` : Nombre de commandes
- `MonetaryTotal` : Somme totale dÃ©pensÃ©e
- `TotalQuantity` : QuantitÃ© totale d'articles
- `Age` : Ã‚ge estimÃ© du client
- `CustomerTenureDays` : DurÃ©e de la relation client
- ... et 29 autres

### Features CatÃ©gorielles EncodÃ©es (70)
- Segments RFM, Types de clients, Saisons prÃ©fÃ©rÃ©es
- RÃ©gions, Pays, Statut du compte
- ... et d'autres

---

## ğŸ“š DÃ©pendances Principales

```
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=1.0.0
matplotlib>=3.4.0
seaborn>=0.11.0
```

---

## ğŸ¯ Objectifs PÃ©dagogiques

Ce projet couvre l'ensemble de la chaÃ®ne de traitement en data science :

| CompÃ©tence | Description |
|------------|-------------|
| **Exploration** | Analyser la qualitÃ© et la structure des donnÃ©es |
| **PrÃ©paration** | Nettoyer, encoder et normaliser les features |
| **Transformation** | RÃ©duire la dimension via ACP (optionnel) |
| **ModÃ©lisation** | Appliquer clustering, classification et rÃ©gression |
| **Ã‰valuation** | InterprÃ©ter les rÃ©sultats et proposer des recommandations |
| **DÃ©ploiement** | CrÃ©er une interface utilisateur avec Flask |

---

## ğŸ“ Notes Importantes

1. **Data Leakage** : Le scaling est appliquÃ© APRÃˆS le split (fit sur train, transform sur test)
2. **Imputation** : Utilisation de la mÃ©diane/mode (pas de KNN comme demandÃ©)
3. **ReproductibilitÃ©** : Random state fixÃ© Ã  42 pour tous les modÃ¨les
4. **Stratification** : Le split prÃ©serve la distribution de la target Churn

---

## ğŸ‘¤ Auteur

**Fadoua Drira**  
Module Machine Learning - GI2  
AnnÃ©e Universitaire : 2025-2026

---

## ğŸ“„ Licence

Ce projet est destinÃ© Ã  des fins pÃ©dagogiques